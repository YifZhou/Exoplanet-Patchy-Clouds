\documentclass[apj]{emulateapj}

\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{natbib}
\bibliographystyle{apj}
\usepackage[breaklinks,colorlinks,citecolor=blue,linkcolor=magenta]{hyperref} 
\shorttitle{Short Title}
\shortauthors{Zhou et al.}

%%% new command %%%
\newcommand{\ima}{\texttt{ima} file}
\newcommand{\flt}{\texttt{flt} file}
\newcommand{\eps}{$\mathrm{e}^{-}/\mathrm{s}$}
\begin{document}
\title{Cloud structure of planetary mass companion AB Pic-b}
\author{Yifan Zhou, Daniel Apai, ...}
\affil{University of Arizona}

\begin{abstract}
...
\end{abstract}

\keywords{kw1, kw2, ...}
\maketitle
\section{Introcduction}

\section{Observation}
\section{Data Reduction}

\subsection{Cosmic Ray Identification}
The WFC3 \texttt{calwf3} pipeline produces two types of calibrated
files per exposure, \ima{} and \flt.  The \ima{} contains all
calibrated non-destructive readouts. The \flt{} is additionally
processed with an up-the-ramp fit that combines every readout into a
single image with a linear regression for every pixel. In the
meanwhile, up-the-ramp fit identifies cosmic ray by searching for
outliers from the fitting result and makes correction
coordinately. \citeauthor{Mandell2013} suggested that time series
extract from {\flt}s have a rms 1.3 times larger than that obtained
from {\ima}s with their transit spectroscopic observation data using
WFC3 IR. Similar result was found in our analysis of WFC3 IR
images. We speculate the larger scattering measured from {\flt}s is
caused by jitter of the telescope, especially when number of sample
per exposure is small. \citeauthor{Swain2013} also recommended to use
non-destructive readouts in data reduction.

We use the last readout in which the peak pixel of AB Pic b's image is
not saturated for every exposure to carry out photometry
measurement. For cosmic ray identification, we take a linear fit to
the sums of pixels in a $7\times7$ box centered on the peak pixel for
all readouts that do not have unsaturated pixel in that region. We
identify exposures that have reduced $\chi^{2}$ values greater than
2.5 as being contaminated by cosmic ray Using this method, there are 9
out 348 exposures that cosmic ray hits were found in the AB Pic b's
image region with this criterion. We did not make correction for these
exposures considering the small number of readouts. Instead we exclude
these images in further analysis. The scatterings of photometry
measurements using files processed in this method is reduced by
factors of 1.65 and 1.41 for F125W data set and F160W data set
coordinately comparing to those measured with {\flt}s, which is
consistent with \citet{Mandell2013}.


\subsection{Continuous Bad Pixels Identification}
Pixels with data quality flags 'bad detector pixels' (DQ = 4),
'unstable response' (DQ = 32), and 'bad or uncertain flat value' (DQ =
512) were masked out as suggested by previous exoplanet transit
spectroscopic observations\citep[e.g.][]{Berta2012, Kreidberg2014}.

\subsection{Flat Field Correction}
\subsection{Primary Star PSF Subtraction}
We removed the point spread function (PSF) of the primary star with
standard roll subtraction method. For one target image, every other
image that was taken with the same filter and different roll angle of
the telescope was selected to form a PSF image cube. The PSF of
primary star was subtracted by its own PSF in the PSF image.  The
position offset of the target image and the PSF image was calculated
with cross correlation. The PSF image was shifted using bilinear
interpolation to align with the target image. By optimizing with least
rms residual in the shaded region shown in Figure \ref{fig:image}, the
amplitude scale of the PSF image was calculated. The PSF image
provided the smallest subtraction residual among images in the PSF
cube was selected as final PSF to be subtracted from target image.

Using images with primary star subtracted with above method, an
average background residual is reached as 2.1 \eps, which is more than
one order of magnitude smaller than the photon noise. Therefore, our
photometry is photon noise limited and we did not attempt to use
more sophisticated PSF subtraction strategy.

\begin{figure}
  \centering
  \plotone{original}
  \plotone{subtracted}
  \caption{One example of the original(upper panel) and primary star
    subtracted (lower panel) images of AB Pic system. In the lower
    panel, white contour defines a region of an annulus with circle
    excluded. The rms residuals were optimized in this region when
    calculation the amplitude scales of PSF images when doing primary
    star image subtraction.}
  \label{fig:image}
\end{figure}
\subsection{Aperture Photometry}

We performed aperture photometry using images processed with above
procedures.  Centroids of PSF of AB Pic b was located by 2 dimensional
Gaussian fit with IDL routine \texttt{mpfit2dpeak}
\citep{Markwardt2009}. Then aperture photometry was calculated using
\texttt{aper} with aperture radius of 3 pixels. Aperture size is
determined by taking into account both reducing noise level as well as
excluding bad pixels.

Photometry uncertainty is the combination of three independent components, readout
noise, photon noise, and fluctuation in the background. We take the
square root of the sum of the squares of the three components as the
uncertainty of one photometry measurement. In fact, the uncertainty is
denominated by photon noise.
\section{Result}
\section{Discussion}
\bibliography{ref.bib}
\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
